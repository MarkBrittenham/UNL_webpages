

\magnification=1200
\overfullrule=0pt
%\parindent=0pt

%\nopagenumbers

\input amstex
\loadmsbm

%\voffset=-.6in
%\hoffset=-.5in
%\hsize = 7.5 true in
%\vsize=10.4 true in

%\voffset=1.4in
%\hoffset=-.5in
%\hsize = 10.2 true in
%\vsize=8 true in

\input colordvi

\def\cltr{\Red}		  % Red  VERY-Approx PANTONE RED
\def\cltb{\Blue}		  % Blue  Approximate PANTONE BLUE-072
\def\cltg{\PineGreen}	  % ForestGreen  Approximate PANTONE 349
\def\cltp{\DarkOrchid}	  % DarkOrchid  No PANTONE match
\def\clto{\Orange}	  % Orange  Approximate PANTONE ORANGE-021
\def\cltpk{\CarnationPink}	  % CarnationPink  Approximate PANTONE 218
\def\clts{\Salmon}	  % Salmon  Approximate PANTONE 183
\def\cltbb{\TealBlue}	  % TealBlue  Approximate PANTONE 3145
\def\cltrp{\RoyalPurple}	  % RoyalPurple  Approximate PANTONE 267
\def\cltp{\Purple}	  % Purple  Approximate PANTONE PURPLE

\def\cgy{\GreenYellow}     % GreenYellow  Approximate PANTONE 388
\def\cyy{\Yellow}	  % Yellow  Approximate PANTONE YELLOW
\def\cgo{\Goldenrod}	  % Goldenrod  Approximate PANTONE 109
\def\cda{\Dandelion}	  % Dandelion  Approximate PANTONE 123
\def\capr{\Apricot}	  % Apricot  Approximate PANTONE 1565
\def\cpe{\Peach}		  % Peach  Approximate PANTONE 164
\def\cme{\Melon}		  % Melon  Approximate PANTONE 177
\def\cyo{\YellowOrange}	  % YellowOrange  Approximate PANTONE 130
\def\coo{\Orange}	  % Orange  Approximate PANTONE ORANGE-021
\def\cbo{\BurntOrange}	  % BurntOrange  Approximate PANTONE 388
\def\cbs{\Bittersweet}	  % Bittersweet  Approximate PANTONE 167
%\def\creo{\RedOrange}	  % RedOrange  Approximate PANTONE 179
\def\cma{\Mahogany}	  % Mahogany  Approximate PANTONE 484
\def\cmr{\Maroon}	  % Maroon  Approximate PANTONE 201
\def\cbr{\BrickRed}	  % BrickRed  Approximate PANTONE 1805
\def\crr{\Red}		  % Red  VERY-Approx PANTONE RED
\def\cor{\OrangeRed}	  % OrangeRed  No PANTONE match
\def\paru{\RubineRed}	  % RubineRed  Approximate PANTONE RUBINE-RED
\def\cwi{\WildStrawberry}  % WildStrawberry  Approximate PANTONE 206
\def\csa{\Salmon}	  % Salmon  Approximate PANTONE 183
\def\ccp{\CarnationPink}	  % CarnationPink  Approximate PANTONE 218
\def\cmag{\Magenta}	  % Magenta  Approximate PANTONE PROCESS-MAGENTA
\def\cvr{\VioletRed}	  % VioletRed  Approximate PANTONE 219
\def\parh{\Rhodamine}	  % Rhodamine  Approximate PANTONE RHODAMINE-RED
\def\cmu{\Mulberry}	  % Mulberry  Approximate PANTONE 241
\def\parv{\RedViolet}	  % RedViolet  Approximate PANTONE 234
\def\cfu{\Fuchsia}	  % Fuchsia  Approximate PANTONE 248
\def\cla{\Lavender}	  % Lavender  Approximate PANTONE 223
\def\cth{\Thistle}	  % Thistle  Approximate PANTONE 245
\def\corc{\Orchid}	  % Orchid  Approximate PANTONE 252
\def\cdo{\DarkOrchid}	  % DarkOrchid  No PANTONE match
\def\cpu{\Purple}	  % Purple  Approximate PANTONE PURPLE
\def\cpl{\Plum}		  % Plum  VERY-Approx PANTONE 518
\def\cvi{\Violet}	  % Violet  Approximate PANTONE VIOLET
\def\clrp{\RoyalPurple}	  % RoyalPurple  Approximate PANTONE 267
\def\cbv{\BlueViolet}	  % BlueViolet  Approximate PANTONE 2755
\def\cpe{\Periwinkle}	  % Periwinkle  Approximate PANTONE 2715
\def\ccb{\CadetBlue}	  % CadetBlue  Approximate PANTONE (534+535)/2
\def\cco{\CornflowerBlue}  % CornflowerBlue  Approximate PANTONE 292
\def\cmb{\MidnightBlue}	  % MidnightBlue  Approximate PANTONE 302
\def\cnb{\NavyBlue}	  % NavyBlue  Approximate PANTONE 293
\def\crb{\RoyalBlue}	  % RoyalBlue  No PANTONE match
%\def\cbb{\Blue}		  % Blue  Approximate PANTONE BLUE-072
\def\cce{\Cerulean}	  % Cerulean  Approximate PANTONE 3005
\def\ccy{\Cyan}		  % Cyan  Approximate PANTONE PROCESS-CYAN
\def\cpb{\ProcessBlue}	  % ProcessBlue  Approximate PANTONE PROCESS-BLUE
\def\csb{\SkyBlue}	  % SkyBlue  Approximate PANTONE 2985
\def\ctu{\Turquoise}	  % Turquoise  Approximate PANTONE (312+313)/2
\def\ctb{\TealBlue}	  % TealBlue  Approximate PANTONE 3145
\def\caq{\Aquamarine}	  % Aquamarine  Approximate PANTONE 3135
\def\cbg{\BlueGreen}	  % BlueGreen  Approximate PANTONE 320
\def\cem{\Emerald}	  % Emerald  No PANTONE match
%\def\cjg{\JungleGreen}	  % JungleGreen  Approximate PANTONE 328
\def\csg{\SeaGreen}	  % SeaGreen  Approximate PANTONE 3268
\def\cgg{\Green}	  % Green  VERY-Approx PANTONE GREEN
\def\cfg{\ForestGreen}	  % ForestGreen  Approximate PANTONE 349
\def\cpg{\PineGreen}	  % PineGreen  Approximate PANTONE 323
\def\clg{\LimeGreen}	  % LimeGreen  No PANTONE match
\def\cyg{\YellowGreen}	  % YellowGreen  Approximate PANTONE 375
\def\cspg{\SpringGreen}	  % SpringGreen  Approximate PANTONE 381
\def\cog{\OliveGreen}	  % OliveGreen  Approximate PANTONE 582
\def\pars{\RawSienna}	  % RawSienna  Approximate PANTONE 154
\def\cse{\Sepia}		  % Sepia  Approximate PANTONE 161
\def\cbr{\Brown}		  % Brown  Approximate PANTONE 1615
\def\cta{\Tan}		  % Tan  No PANTONE match
\def\cgr{\Gray}		  % Gray  Approximate PANTONE COOL-GRAY-8
\def\cbl{\Black}		  % Black  Approximate PANTONE PROCESS-BLACK
\def\cwh{\White}		  % White  No PANTONE match


\loadmsbm

\input epsf

\def\ctln{\centerline}
\def\u{\underbar}
\def\ssk{\smallskip}
\def\msk{\medskip}
\def\bsk{\bigskip}
\def\hsk{\hskip.1in}
\def\hhsk{\hskip.2in}
\def\dsl{\displaystyle}
\def\hskp{\hskip1.5in}

\def\lra{$\Leftrightarrow$ }
\def\ra{\rightarrow}
\def\mpto{\logmapsto}
\def\pu{\pi_1}
\def\mpu{$\pi_1$}
\def\sig{\Sigma}
\def\msig{$\Sigma$}
\def\ep{\epsilon}
\def\sset{\subseteq}
\def\del{\partial}
\def\inv{^{-1}}
\def\wtl{\widetilde}
\def\del{\partial}
\def\delp{\partial^\prime}
\def\delpp{\partial^{\prime\prime}}
\def\sgn{{\roman{sgn}}}
\def\wtih{\widetilde{H}}
\def\bbz{{\Bbb Z}}
\def\bbr{{\Bbb R}}
\def\bbh{{\Bbb H}}



\ctln{\bf Math 856 Differential Topology}

\ssk

\ctln{Ever-expanding course notes}

\msk


Differential topology is about introducing concepts and methods from calculus to the
realm of topological spaces. That is, we wish to use notions of differentiation
and integration in a topological setting. There are (at least) two reasons for doing
so. The first is, essentially, waste not want not; lots of people have put in a lot
of effort into developing the tools of analysis, why shouldn't topologists want to take
advantage of all of that body of work? Any tool that we can bring to bear to better
understand topological spaces helps us, well, understand topological spaces better.
The other reason is that by figuring out how to introduce analysis into topology,
we will have extended the range of applicability of these concepts. Experience has
also shown that the topological point of view can, in hindsight, provide a more natural
setting for many problems of analysis. It can also provide a natural framework for
explaining some of its results; Stokes' Theorem is perhaps the first and most well-known,
but certainly not the only such result that we may encounter in our study.
As with nearly any branches of mathematics,
once you figure out how to reconcile the immediate difficulties in introducing one
subject to another (analysis to topology, or topology to analysis?), you discover
innumerable ways in which they open up new avenues of exploration, and neither 
subject is ever the same again. The goal of this course is to explore the ways in 
which we can bring analysis and topology together, and some of the ways in which 
anaysis helps to illuminate the study of topology.

\msk

Our first task is to determine {\it which} topological
spaces we can reasonably introduce such concepts and methods to.

\ssk

{\bf Manifolds:} A basic principle in topology is that a topological space is explored
through its continuous functions/continuous maps, both in and out of the space. 
Calculus as we usually encounter it applies to functions between Euclidean spaces
$\bbr^n$. We have derivatives, partial derivatives, integrals, and multipe integrals,
and many variations, depending upon what domain or range/codomain we choose for 
our functions. So if we want to be able to introduce the idea of a ``differentiable''
map, the simplest tack to take is to look at topological spaces which ``behave''
like Euclidean spaces. Differentiability is a local property; a (partial) derivative
of a function at a point (much less whether you have one, i.e., are
differentiable) depends only on the values of the function near that point.
Of course the notion of ``local'' is in some sense what a topology on a space
is designed to describe; open neighborhoods of a point $x$ are precisely the sets
describing which points are ``near'' $x$. So on a most basic level, the topological 
spaces most naturally to introduce calculus to are those in which the the points have
open neighborhoods which ``look like'' the spaces that we know how to do calculus on,
namely, Euclidean spaces. This motivates our first definition.

\msk

A {\it topological manifold} $M$ of dimension $n$ is a Hausdorff, second countable
space with the property that for every $x\in M$ there is an open neighborhood $U$ of
$x$ which is homeomorphic to $\bbr^n$.

\msk

The shorthand for the last property is that $M$ is {\it locally Euclidean}. The other
two properties, Hausdorffness and second countability, are designed, really, to make 
the topologists job easier. One occasionally encounters situations in which a locally
Euclidean space is either not Hausdorff or not second countable, but they are very
much the exception rather than the rule. And being able to assume both conditions
when someone starts tossing the term ``manifold'' around certainly make proving theorems
a lot easier. Surely this isn't the first time that you have encountered hypotheses
being imposed for the purpose of making theorems easier to prove? At any rate, any
subset of a Euclidean space is both Hausdorff and second countable in the subspace 
topology; most (all?) manifolds we will meet can (with effort) be interpreted as 
such a subspace. A manifold of dimension $n$ will be called an $n$-manifold for short.
It is not at all clear from the definition, but it is the case that the $n$ of $n$-manifold
is a homeomorphism invariant. At a given point $x\in M$, this follows from a result 
called the Invariance of Domain;
which says that if $U\subseteq \bbr^n$ is open, and $f:U\rightarrow \bbr^n$ is 
continuous and one-to-one, then $f(U)\subseteq \bbr^n$ is also open. (The cleanest proof
uses homology theory, and can usually be found in any decent algebraic topology text.)
It is a direct consequence that no open set $U\subseteq \bbr^n$ can be homeomorphic to 
an open subset of $\bbr^m$ for $m\neq n$ (and so can't be homeomorphic to $\bbr^m$, either).
This also means that in a connected manifold, every point has neighborhoods locally
homeomorphic to the same $\bbr^n$; this can be verified by the usual trick of showing that
for a fixed $n$, the points with neighborhoods homeomorphic to $\bbr^n$ is open (and 
therefore also closed!).

\msk

{\bf Examples:} Some standard examples: Euclidean space $\bbr^n$ itself. Spheres $S^n$ = the points
at unit distance in $\bbr^{n+1}$; given a point, $x\in S^n$ at least one of its
coordinates $x_i$ is non-zero. Then the set of points $y\in S^n$ whose $i$-th 
coordinate has the same sign as $x$ form a locally Euclidean neighborhood of $x$;
the homeo to the unit ball in $\bbr^n$ is given by projection onto the other
coordinates. Cartesian products of manifolds are manifolds; take the Cartesian
product of neighborhood in each as your local models. Open subsets of
manifolds are manifolds. These basic building blocks already let you build
a wide variety of examples.

\msk

Once we are confortable with the setting, manifolds, into which we will ultimately introduce
differentiability, we are left with actually {\it doing} it. It turns out that in order
to do so in a meaningful way, we have to introduce additional ``structure''; simply
having a topological manifold won't be enough.

\ssk

{\bf Smooth functions:} On the face of it, once we have a space $M$ which locally 
``looks like'' Euclidean space,
we can seemingly define differentiability at a point for any function $f:M\rightarrow \bbr$.
Given a point $x\in M$, we have, by definition, a neighborhood $U$ of $X$ and a
homeomorphism $h:U\rightarrow \bbr^n$. This is, at least, enough to {\it describe}
a function for which differentiability makes sense, namely the composition
of $h^{-1}$ with the restriction of $f$ to $U$; $f\circ h^{-1}:\bbr^n\rightarrow \bbr$.
So as a first approximation, we could say that $f$ is differentiable at $x$ if 
$f\circ h^{-1}$ is differentiable at $h(x)$.

\ssk

There is only one problem with this. Surely if we are generalizing the notion of 
diferentiability to more general spaces we don't want to {\it change} what functions
$g:\bbr^n\rightarrow \bbr$ we wish to consider to be differentable. But, technically,
our first attempt at a definition just did. Consider the function $f(x)=|x|$, which 
we are all, presumably, willing to agree is not differentiable at $0$. But we can 
treat the domain $\bbr = M$ as a 1-dimensional manifold, where $U=\bbr$ and
the homeomorphism $h(x)=x^{1/3}$ serves as the proof for each $x\in M$ that $M$
is locally Euclidean. But then in testing whether or not $f$ is differentiable 
at $0$, we can just check that $f\circ h^{-1}(x) = |x^3|$ is in fact differentiable
at $0$. Which it is; the derivative is $0$.


{\bf Charts:} What went wrong? Nothing. Unless you don't want to change the notion of 
differentiability... The point is, our definition of differentiability mentions
both a neighborhood $U$ of $x$ (which won't, in the end, really affect things)
and a specific homeomorphism $h:U\rightarrow \bbr^n$. The function $f$ and the point
$x$ wasn't enough to define differentiability; we also needed a {\it chart}
$(U,h)$, that is, a specific description for {\it how} to identify a neighborhood
of $x$ with $\bbr^n$. And whether or not we decide $f$ is differentiable depends
on which chart we pick. (In our example above, if we chose the identity map to define
our chart, we would have decided that $f(x)=|x|$ is not differentible at $0$.)
So, in order to {\it unambiguously} decide if a function is differentiable, we
need to restrict which pairs $(h,U)$ we are willing to allow ourselves to use 
as charts. This special collection of charts is the extra structure that we need.

\ssk

What is the basic idea? We wish to find some way to ensure that if one of two
charts $(U,h)$ and $(V,k)$ with $x\in U,V$ tells us that $f$ is differentiable 
at $x$, then the other chart {\it must} do so, as well. That is, we wish to guarantee
that $f\circ h^{-1}$ is differentiable at $h(x)$ iff $f\circ k^{-1}$ is differentiable 
at $k(x)$. And how to do this? The Chain Rule to the rescue! The thing which connects
$f\circ h^{-1}$ to $f\circ k^{-1}$ is a {\it transition map} 
$k\circ h^{-1}$; $f\circ h^{-1} = (f\circ k^{-1})\circ (k\circ h^{-1})$.
This equality holds on $h(U\cap V)$, which is the image under a homeo of an 
open subset of $U$ containing $x$, so is an open subset of $\bbr^n$ contining $h(x)$.
And if $k\circ h^{-1}$ is differentiable, then Chain Rule 
tell us that $f\circ k^{-1}$ differentiable 
at $k(x)$ implies $f\circ h^{-1}$ differentiable at $h(x)$. The reverse 
implication follows from knowing that $h\circ k^{-1}$ is differentiable.

\ssk

{\bf Atlases:} This leads us to our basic construction. A $C^{(k)}$ {\it atlas} ${\Cal A}$ on a 
topological manifold $M$ is a collection $(U_i,h_i)$ of charts on $M$ so that 
(1) $\bigcup U_i=M$ and (2) for every $i,j$ with $U_i\cap U_j\neq \emptyset$,
$h_i\circ h_j^{-1}:h_i(U_i\cap U_j)\rightarrow h_j(U_i\cap U_j)$ is $C^{(k)}$,\
that is, has continuous partial derivatives through order $k$. Note that
notationally, by reversing the roles of $i$ and $j$, we are also insisting
that $h_j\circ h_i^{-1}$ be $C^{(k)}$. Given a $C^{(k)}$ atlas ${\Cal A}$ on a manifold
$M$, we can then unambiguously define differentiatible functions,
or $C^{(m)}$ functions for any $m\leq k$, $f:M\rightarrow \bbr$,
by requiring that $f\circ h_i^{-1}:h(U_i)\rightarrow \bbr$ is $C^{(m)}$, for every $i$.
More generally, given atlases on manifolds $M,N$, we can define a map
$f:M\rightarrow N$ to be {\it differentiable } by requiring that 
$k_j\circ f\circ h_i^{-1}$ is differentiable
for every $k_j$ in the atlas for $N$ and $h_i$ in the atlas for $M$. 

It will be useful to introduce some notation at this point, so that we don't 
have to keep writing `` $h\circ k^{-1}$ is $C^{(k)}$ ''; we will say that $h$ and $k$ are 
`` $C^{(k)}$-related '' if $h\circ k^{-1}$ and $k\circ h^{-1}$ are both $C^{(k)}$. 

\msk

{\bf Smooth structures:} A $C^{(k)}$ atlas is enough to be able to define $C^{(m)}$ 
functions for $m\leq k$, but from 
a philosophical ( and functional) point of view, some atlases are better than others. 
If $f:M\rightarrow\bbr$
is a $C^{(m)}$ function and $(h,U)$ is a chart on $M$, and $V\subseteq U$ is open,
then
$f\circ (h|_V)^{-1}:h(V)\rightarrow \bbr$, as the restriction of $f\circ h^{-1}$, is $C^{(m)}$.
In fact, $h|_V$ is $C{(k)}$-related to every chart on $M$ (if we started with a $C^{(k})$
atlas), and so it doesn't hurt to add $h|_V$ to our atlas; it won't alter what functions
we will call $C^{(m)}$. But it {\it might} actually help! We re all no doubt familiar
with $\epsilon$-$\delta$ arguments where we keep shrinking $\delta$ (effectively, shrinking
the neighborhood of some point $x$) in order to make better things happen. The same will be
true here; we will want to shink the domains of charts in order to make good things happen.
It would be nice if such domains were already part of our atlas. So, we do the natural
thing; just toss them in. And while we're at it, we might as well toss in everything that
we can for free (without changing what we'll call a smooth map). This turns out to be
everything which is $C^{(k)}$-related to {\it everything} already in our atlas. This is
also the {\it largest} $C^{(k)}$ atlas which contains our original atlas. Such an
atlas is called a {\it maximal} atlas.

A {\bf $C^{(k)}$ structure} on a manifold $M$, $0\leq k\leq \infty$, is a maximal
$C^{(k)}$ atlas on $M$. $M$, together with a $C^{(k)}$ structure, will be called
a $C^{(k)}$ manifold. A $C^{(0)}$ manifold is ``just'' a manifold;  a $C^{(0)}$ structure
is a collection of homeomorphisms from the sets of an open cover of $M$ to $\bbr^n$
(that the transition maps are $C^{(0)}$, i.e., continuous, is automatic). In general
we will content ourselves to study $C^{(\infty)}$ structures on manifolds, but it 
is important to know that there are other possible choices. (When an author never
needs anything beyond a second derivative, they will often talk only about 
$C^{(2)}$ manifolds, for example. It is a fact (see, e.g., Hirsch, {\it Differential
Topology}, p.51) that for every $1\leq r\leq s\leq \infty$, a $C^{(r)}$ structure $\Cal A$
on a manifold $M$ {\it contains} a $C^{(s)}$ structure $\Cal B\subseteq \Cal A$;
that is, $\Cal A$ contains an atlas which is $C^{(s)}$-compatible. 
But we will likely not use this result.)

\msk


{\bf Examples:} Our standard examples of manifolds above also provide some standard examples of smooth
manifolds; one merely needs to verify that the charts that we built are $C^{(\infty)}$-related,
so that the have an atlas, and then wave our magic wand to `build' the corresponding
maximal atlas. Restriction to an open set and Cartesian product both
preserve smoothness, so we have several general approaches to building smooth
manifolds at our fingertips.

\msk

{\bf Diffeomorphisms:} Just as in topology we have a notion, homeomorphism, which allows us to 
treat two spaces as essentially the ``same'', there is a corresponding 
notion of same in the smooth setting. Two $C^{(k)}$ manifolds $(M,{\Cal A}),(N,{\Cal B})$
are {\it diffeomorphic} if there is a $C^{(k)}$ bijection $f:M\rightarrow N$ with
$C^{(k)}$ inverse. Just as with a homeomorphism, a diffeomorphism induces a
bijection between charts of $M$ and $N$, via 
$h:U\rightarrow \bbr^n$, for $U\subseteq M$, is taken to 
$h\circ f^{-1}:f(U)\rightarrow \bbr^n$. Because $f^{-1}$ is $C^{(k)}$, this
map is $C^{(k)}$, hence is in the (maximal) atlas ${\Cal B}$.


{\bf Some history:} Just as in the ``standard'' definition of topology, the field of 
differential topology 
can be most succintly described as the study of the properties of smooth manifolds that
are invariant under diffeomorphism (i.e., are defined in terms of the smooth
structure). You will have learned in the homework that a given manifold can have
many different smooth structures, meaning that the atlases defining them are distinct.
But in many cases these atlases can still define the `same' smooth
structure, that is, they are diffeomorphic. In particular, up to diffeomorphism,
$\bbr$,$\bbr^2$,$\bbr^3$, and $\bbr^n$ for $n\geq 5$ all have unique differentiable 
structure. (Except for $\bbr$, these are all fairly difficult results to establish!)
It was a major breakthrough of the mid-1980's that $\bbr^4$ was discovered
to have more than one smooth structure; it in fact has uncountably many non-diffeomorphic
smooth structures. In fact, there are uncountably many open subsets of standard
$\bbr^4$, each homeomorphic to $\bbr^4$, but (using the smooth
structures it inherits from standard $\bbr^4$) {\it none}
of them diffeomorphic to one another! If this isn't wierd enough
for you, consider that, since $\bbr^5$ has only one smooth structure,
up to diffeo, if you take these `exotic' $\bbr^4$'s and cross them with
$\bbr$ (with the standard structure), you obtain smooth manifolds, {\it all}
of which are diffeomorphic to standard $\bbr^5$ (and hence to one another)!

Every 2-manifold has a unique smooth structure up to diffeo (Rado, 1920s?);
the same is true for 3-manifolds, as well (Moise, 1950's). 
But there actually exist 4-manifolds which
posess {\it no} smooth structure. This was first discovered as a result of work of
Freedman and Donaldson (for which both received the Fields Medal in 1986). Freedman
showed that simply-connected (meaning every map of
a circle into $M$ extends to a map of a disk) topological 4-manifolds were determined
up to homeo by their `intersection pairing on second homology' (whatever
that is), and further, every unimodular symmetric bilinear pairing has a corresponding manifold.
This, by the way, implies the topological 4-dimensional Poincar\'e conjecture.
Donaldson, on the other hand, showed that for simply-connected {\it smooth} 
4-manifolds, certain intersection pairings could not arise (if the pairing is
positive definite, then it is diagonalizable). His work essentially
involved PDE's on 4-manifolds. In particular, the
pairing known as ``E8'' could not occur. So the 4-manifold ``E8'', which Freedman's work shows
exists, has no smooth structure. Similar examples can be found for all 
higher dimensions, as well.

On the other hand, there are manifolds which have `too many' smooth structures, i.e., admit
multiple structures which are not diffeomorphic to one another. $\bbr^4$ is the most famous example
these days, but it turns out that most spheres have this property, as well. In the late 1950's
John (`Jack') Milnor showed that $S^7$ has more than one smooth structure; it was later shown that
it has exactly 28 non-diffeomorphic structures. $S^{31}$ has more than 16 million! And in case you
think these structures are really wierd things that you are never likely to meet, the 28
structures in $S^7$ arise on the links of singularities of algebraic surfaces. Specifically,
the intersection of the solutions (in ${\Bbb C}^5$) to the equation

\centerline{$a^2 + b^2 + c^2 + d^3 + e^{6k - 1} = 0$}

\noindent with a small sphere centered at the origin, for $k=1,\ldots ,28$, gives all
28 exotic 7-spheres (source: the Wikipedia entry for `exotic sphere').
While wandering the web, I found an assertion (by Ron Stern) that `all known 4-manifolds
have infinitely many distinct smooth structures', but I am not sure how to interpret that...
A result of Kirby and Siebenmann from the 1960's says that, except possibly in dimension 4
(unless Ron Stern's statement deals with it?), every smooth $n$-manifold $M^n$ has the same number
of non-diffeomorphic smooth structures as $S^n$ does. So {\it every} smooth 7-manifold has
28 distinct smooth structures, up to diffeomorphism...

\ssk

Aside from being interesting and suprising facts, proved by really bright people, these kinds 
of results can have useful consequences. Since all 2- and 3-manifolds $M$ have unique smooth 
structures, when somebody hands us such a manifold $M$, we can {\it assume} they have also 
handed us a smooth structure (even if they didn't); it comes for free. Even more, we don't
need to worry about which smooth structure we might have picked; if you and I happen to have
picked different ones to work with, any result you might find with yours can be translated
into a result about mine, because we know that there is a diffeomorphism between them (we just
might not know what it {\it is}...). And if we are trying to set up some problem or do some
computation, we can choose the most convenient coordinate system (i.e., atlas) that we want
(tailored to the functions involved, perhaps), to carry out our work; we know, again, that we
can translate our results into any other coordinate system, since they all describe the 
`same' smooth structure. The fact that this isn't true in dimensions 4 and above (except, 
technically, that the Kirby-Siebenmann results implies, for example, that all smooth 12-manifolds 
have unique smooth structures?) makes life in higher dimensions much more interesting, in 
this regard! 

\msk

{\bf Manifolds with boundary:} Our definitions so far do not allow for things like the unit
interval $I=[0,1]$ to be a manifold, much less a smooth one. And, semantically at least,
they never will be; they will be {\it manifolds with boundary}. A manifold with boundary is
a Hausdorff, second countable space in which every point has a neighborhood homeomorphic
to {\it either} $\bbr^n$ {\it or} the upper half space ${\Bbb H}^n = \{(x_1,\ldots ,x_n)\in\bbr^n : 
x_n\geq 0\}$. Points which do not have a neighborhood homeomorphic to $\bbr^n$ are called
boundary points; the union of them is the boundary of $M$, denoted $\del M$. It is a 
consequence of Invariance of Domain that if $x\in M$ has neighborhood homeomorphic to 
${\Bbb H}^n$ and the image of $x$ has last coordinate $0$, then $x\in \del M$; that is,
{\it every} chart is homeomorphic to ${\Bbb H}^n$, not $\bbr^n$, and always sends $x$ to the 
boundary. Putting a smooth structure on a manifold with boundary involves some extra
requirements as well, motivated, mostly, by what analysts have found to be reasonable
in dealing with regions with boundary in Euclidean space. That is, a map ${\Bbb H}^n\rightarrow \bbr$
is $C^{(k)}$ if it can be {\it extended} to a $C^{(k)}$ map 
$\bbr^{n-1}\times (-\epsilon,\infty)\rightarrow \bbr$ on an open neighborhood of ${\Bbb H}^n$.
Then we can adopt the exact same definition of an atlas and smooth structure, using
this augmented definition of smooth to test the compatibility of the charts; that is, for
any point $x$ on the boundary, the maps $h\circ k^{-1}$ and $k\circ h^{-1}$ must extend to smooth 
maps on open neighborhoods of $k(x)$ and $h(x)$ respectively. The boundary $\del M$ of a smooth
manifold $M^n$ is a smooth manifold of dimension $n-1$; the restrictions of the charts to 
$\del\bbh^n=\bbr^{n-1}\times \{0\}$ form a smooth atlas, since the original charts are smooth;
we just ignore any partial derivatives in the $n$-th direction.

\msk

{\bf Smooth maps:} So what do you do when you have a smooth structure? 
Start building smooth maps!
We know how to identify a smooth map $f:M^n\rightarrow N^m$; we must have
$h\circ f \circ k^{-1}:K(V)\rightarrow h(U)$ smooth for every pair of charts
on $M$ and $N$. Note that it is enough, though, to verify this for charts in 
a pair of atlases contained in the smooth structures for $M$ and $N$; the 
compatibility of every other chart in our smooth structure with those of the atlases
will guarantee smoothness of $h\circ f \circ k^{-1}$ over the entire maximal atlas.
(Note also that this does {\it not} contradict what you've shown in one of your
homework problems!) So, for example, to verify that some function $f:S^5\rightarrow S^8$
(using the standard smooth structures!) is smooth, it suffices to use an atlas 
consisting to two charts on each (the stereographic projections from the poles),
so smoothness can be verified by examining only 4 functions from $\bbr^5$ to $\bbr^8$.
Actually verifying that such functions {\it are} smooth we are going to mostly leave
to the same slightly fuzzy realm one encounters in calculus: if it is built up 
out of functions that we ``know'' are smooth, then it is smooth wherever it is 
defined. 

One thing that can help us in things is to recognize that smoothness is local.
This is just like in topology, where continuity is local; if $f:M\rightarrow N$
is a map such that for every $x\in X$ there is a chart $(h,U)$ for $M$ with $x\in U$
and a chart $(k,V)$ for $N$ with $f(x)\in V$, and $h\circ f\circ k^{-1}$ is smooth
(where it is defined), 
then $f$ is smooth. This is simply because the $h$'s and the $k$'s form atlases
for $M$ and $N$, respectively. But if you turn it around it can be thought of as a prescription
for building a smooth function, by patching together smooth functions defined on open sets;
if $\Cal O$ is an open cover of $M$, and for each $U\in {\Cal O}$ we have a
smooth map $f_U:U\rightarrow N$ such that $f_U=f_V$ on $U\cap V$ for every $U,V\in {\Cal O}$,
then the map $f:M\rightarrow N$ defined by `$f(x)=f_U(x)$ if $x\in U$' is smooth. This is
the direct analogue of the Gluing Lemma from topology. Of course, in topology, one more
often wants to glue together maps defined on {\it closed} sets, rather than open sets;
it is less messy. But in the smooth setting things aren't nearly so nice;
on $\bbr$ the function $f(x)=|x|$ can be obtained by gluing together two smooth
functions, but it is not smooth (using the standard smooth structures!) Question:
are there {\it other} smooth structures on $\bbr$ for which $f$ {\it is} smooth?

{\bf Basic properties:} We also have many of the standard results. The composition of two smooth maps is smooth;
this is essentially just because the corresponding result is true for maps between
Euclidean spaces. The sum, difference, and product of two smooth maps $M\rightarrow\bbr$
are all smooth; again, this is basically because this is true for maps from $\bbr^n$ to $\bbr$.
And the quotient is smooth so long as the denomenator is never zero. And a map into a Cartesian 
product of smooth manifolds (using the product smooth structure) is smooth iff the map into
each factor is smooth (i.e., the composition with projection onto each factor is smooth). 
This last fact you have probably already had to use, since to decide
on the smoothness of $h\circ f \circ k^{-1}:K(V)\rightarrow h(U)\subseteq \bbr^m$, 
you had to look at each of the $m$ coordinate functions (projecting onto each coordinate 
factor $\bbr$). But some things {\it don't} work; for example the maximum $\max\{f,g\}$
of two smooth functions (mapping to $\bbr$) {\it need not} be smooth; $h(x)=|x|$, for example, can 
be defined as the maximum of the functions $f(x)=x$ and $g(x)=-x$.

\ssk

Technically, partial derivatives are taken with respect to coordinate charts, not variables.
but if $h:U\rightarrow \bbr^n$ is a chart, and $f:M\rightarrow \bbr$ is a map, then
if we adopt the notation that $h(z)=(x^1(z),\ldots ,x^n(z))\in \bbr^n$, we will adopt 
the notation that 

\ctln{$\displaystyle {{\partial}\over{\partial x^i}}(f)(z) = 
{{\partial}\over{\partial x_i}}(f\circ h^{-1})(h(z))$}

\noindent That is, we formally are taking the partial derivative of $f$ with respect to the
coordinate functions of the chart $h$. Therefore, a function does 
not really have a `value' of a partial derivative at a point; it has such a value 
{\it with respect to} a given coordinate chart. If we change charts around a point, to
$(k,V)$, $k=(y^1,\ldots ,y^n)$ the Chain Rule tells us how to relate the two sets of 
partial derivatives; it works out to the familiar

\ctln{$\displaystyle {{\partial f}\over{\partial y^i}} = 
\sum_i{{\partial f}\over{\partial x^i}}{{\partial x^i}\over{\partial y^j}}$}

\noindent (once you chase it through the notation). One thing that this formula
immediately tells us is that if $\partial f/\partial x^i = 0$ at $z$ for every $i$,
using one coordinate chart, 
then $\partial f/\partial y^i = 0$ at $z$ for every $i$, for any other chart;
a linear combination of $0$'s is still $0$. So the notion of a {\it critical point},
as in mulrivariate calculus, is still well-defined in our more general setting. And
the usual proof that local max's and min's are critical points carries over as
well (apply any proof you've ever seen to $f\circ h^{-1}$ for any chart around
your local extremum). So we can, for example, formulate and solve max-min problems
on smooth manifolds!

\msk

{\bf Partitions of unity:} There will be many situations in the material to come where we will want to assemble information
obtained locally into a single smooth map $f:M\rightarrow N$. To do so, we will introduce the
notion of a {\it partition of unity}; this is a way of writing the function $f(x)=1$ as a sum
of smooth functions $1=\sum g_i$. Of course, $f(x)=1$ works; constant functions are smooth. 
But we will want each
summand function to be `local'; that is, zero outside of a small open set (think: the domain of a chart).
For example, in order to define the integral of a function $f:M^n\rightarrow \bbr$, the idea will be to 
define it first over the domain of a chart $(h,U)$ (as the integral in $\bbr^n$ of the function
$f\circ h^{-1}$, essentially), and then define the integral of $f$ as the sum of the integrals
of $f\cdot g_i$ (which are `really' integrals over $\bbr^n$), since $f = f\cdot 1 \sum f\cdot g_i$.
Building such a collection of functions will take a bit more work, and will be the first time we 
really invoke the Hausdorffness and
second countability conditions built into our original definition. 
Put slightly differently, the idea is that 
we want to make the
{\it support} of each function, supp$(g_i)$ = cl($\{x\in M : g_i(x)\neq 0\}$), to be small.


Given an open cover ${\Cal O}$ of a space $M$, a {\it locally-finite refinement} of ${\Cal O}$
is an open cover ${\Cal P}$ of $M$ so that for every $P\in{\Cal P}$ there is an $O\in{\Cal O}$
so that $P\subseteq O$ (that's the refinement part), and for every $x\in M$ there
is an open neighborhood $x\in U$ of $x$ so that $U\cap P=\emptyset$ for all but finitely many
$P\in {\Cal P}$ (that's the locally finite part). A space $M$ is {\it paracompact} if 
every open cover ${\Cal O}$ has a locally finite refinement ${\Cal P}$ such that $\overline{P}$ is compact
for every $P\in {\Cal P}$. Such $P$ are called {\it precompact}.

The main result we are aiming at is:

\ssk

If $M$ is a smooth manifold and ${\Cal O}=\{u_\alpha : \alpha\in I\}$ is an open cover of $M$, then there
is a partition of unity $\{g_i : i\in I\}$ so that supp$(g_i)\subseteq U_i$, and for every $x\in M$,
there is a neighborhood $V$ of $x$ so that only finitely many supp$(g_i)$ intersect $V$.

\ssk

The statement that supp$(g_i)\subseteq U_i$ is referred to as having a partition of unity
{\it subordinate} to the open cover.
The last property of the statement allows us to make sense of adding the functions together; we don't
need the convergence of some infinite series, since around every point all but finitely many of the
functions take the value zero. We say that the supports of the functions are {\it locally finite},
for short.

The proof of the existence of partitions of unity essentially comes in two parts. The first part
asserts that any open cover ${\Cal O}$ of $M$ has a {\it locally finite refinement}, that is, a 
locally finite cover ${\Cal O}^\prime$ so that for every $O\in {\Cal O}$ there is an 
$O^\prime\in{\Cal O}^\prime$ with $O^\prime\subseteq O$ (i.e., the refinement has ``smaller'' sets).
This property is known as {\it paracompactness}. In particular, we will show that the refinement
can be built out of the domains for coordinate charts of $M$. The second part uses the 
refinement by coordinate charts to build the partition of unity, by building a collection of 
smooth ``bump'' functions supported on each coordinate chart.

\ssk

{\bf Paracompactness:} To prove paracompactness, start with an open cover $\Cal O$ of $M$, and a countable basis $\Cal B$
for the topology on $M$. First we need a locally 
finite open cover to help guide our steps. Every point $x\in M$ is in the domain of some 
chart $h:U\rightarrow \bbr^n$ (with, we can arrange, image containing $B(h(x),2)$). The 
open sets $U_x=h^{-1}(B(h(x),1))$ cover $M$, and have compact closure; and for each there is 
a basis element $B_x$ with $x\in B_x\subseteq U_x$. Since $\Cal B$ is countable, 
there are countably many $x_i$ so that the $B_{x_i}$, and therefore the $U_{x_i}$,
cover $M$. Call these sets $U_i, I\in {\Bbb N}$, and let $C_i=\overline{U_i}$. By construction,
$C_i$ is compact, so for any finite set $I\in{\Bbb N}$, $C_I=\bigcup_I C_i$ is compact. 
Let $E_I$ denote $\bigcup_I U_i$.
Set $I_1=\{1\}$, then since the $U_i$ cover $M$ and therefore $C_1$, there are finitely
many $i$ with union $J_2$ so that $C_{I_1}\subseteq \bigcup_{J_2}U_i$, and set $I_2=J_2\cup\{2\}$.
Inductively, we continue to build finite sets $J_n$ so that $C_{I_{n-1}}\subseteq \bigcup_{J_n}U_i$
and $I_n=J_n\cup\{n\}$. Then $M=\bigcup_n C_{I_n} = \bigcup_n E_{I_n}$, $C_{I_{n-1}}\subseteq E_{I_n}$
$C_{I_n}$ is compact and $E_{I_n}$ is open. Then the sets 
$K_n=E_{I_n}\setminus C_{I_{n-2}}$ are open, have union $M$, have compact closure (contained in $C_{I_n}$),
and are locally finite. To demonstrate
the last assertion, for any $x\in M$, 
$x\in E_{I_n}$ for some $n$; assume $n$ is minimal. Then $x\in U_j$ for some $j\in I_n$, and since
$U_j\subseteq E_{I_n}\subseteq E_{I_k}$ for all $k\geq n$, $U_j\cap K_r=\emptyset$ for all $r\geq n+2$.
In fact, since $\overline{K_r}\subseteq C_{I_n}\setminus E_{I_{n-1}}$, only $K_{r-1}, K_r$, and $K_{r+1}$
meet $\overline{K_r}$.

\ssk

Now start again. We have our open cover ${\Cal O}$, and the locally finite cover $\{K_n\}$ by 
precompact open sets. For every point $x\in M$ we can, by local finiteness, find an open neighborhood $W_x$ so that
if $x\in K_n$ then $W_x\subseteq K_n$; start with a neighborhood meeting only fnitely many of them, and then
intersect it with each of them as well. Taking a further intersection with an element of $\Cal O$ containing
$x$, we can also assume that $W_x\subseteq U\in {\Cal O}$. Then we may assume by intersecting with 
the domain of a chart
that there is a chart $h:W_x\rightarrow \bbr^n$ sending $W_x$ to an open neghborhood of $h(x)$. Rescaling
$h$ on the codomain side and shrinking the domain, we can asuume that $h(W_x)=B(h(x),2)$, and 
so $V_x=h^{-1}(B(h(x),1))$ is a neighborhood of $x$ with compact closure, contained in an element of
$\Cal O$, and contained in every $K_n$ that it meets. $W_x$ satisfies all of these properties
except possibly the compact closure.

Now for each $n$, the sets $V_x$ with $x\in \overline{K_n}$ form an open cover of the compact set $\overline{K_n}$,
so they have a finite subcover ${\Cal P}_n=\{V_{x_1,k]n},\ldots ,V_{x_{m_n},kn}\}$; we assume that each
has non-empty intersection with $\overline{K_n}$ (otherwise we throw it away). 
Set ${\Cal R}_n=\{W_{x_1,n},\ldots ,W{x_{m_n},n}\}$. The collectionS
$\Cal P=\bigcup_n{\Cal P}_n$  and ${\Cal R}=\bigcup_n{\Cal R}_n$ both form open covers of $M$, are
refinements of $\Cal O$, and, we now show, are locally finite. It is enough to show this for $\Cal R$,
since these sets are larger. We show that, in fact, each set in $\Cal R$ meets only
finitely many others, so each demonstrates local finiteness for every point in it.
But each $W=W_{x_i,n}$ intersects, and is therefore contained in, some $K_m$. 
It therefore meets only $\overline{K_{m-1}}, \overline{K_m}$, or $\overline{K_{m+1}}$. 
Any other element $W^\prime$ of $\Cal R$ meeting $W$ meets, and therefore is contained in, one of these three
sets. So the only $\overline{K_r}$ it could meet would be one of $\overline{K_{m-2}}$
through $\overline{K_{m+2}}$. $W^\prime$ is therefore a member of one of ${\Cal R}_{m-2}$ through
${\Cal R}_{m+2}$; it doesn't meet any of the other sets $\overline{K_r}$. Therefore, it is
one of the finitely many elements of these five sets. So $W$ meets only finitely many of the other
elements of $\Cal R$. 

\msk

{\bf The partitioning of 1:} Now that we know how to build a locally finite cover by (images of) charts $(h_i,h_i^{-1}(B(x_i,2))$
for which $h_i^{-1}(B(x_i,1))$ also cover and $h_i^{-1}(\overline{B(x_i,1)})$ is compact, we turn 
to bulding a partition of unity with supported on these sets. We start with the fact
that the function

\ctln{$f(x)= e^{-1/x} \text{ if } x>0$ ; $=0 \text{ if } x\leq 0$}

\noindent is $C^\infty$. This follows from the fact that the $n$-th derivative of
$e^{-1/x}$ is $f_n(x)=p_n(x)e^{-1/x}/x^{2n}$ for some polynomial $p_n(x)$, which can be established
by induction on $n$. The function has (one-sided) limit $0$ at $x=0$, which can be established by
repeated use of L`H\^opital's Rule (to show that $e^{-1/x}/x^{2n}$ has limit 0). 
Together these imply that $f$ has continuous derivatives of'all orders. Note that since
$-1/x<0$ for $x>0$, $0\leq f(x) <1$ for all $x$. Now define 
$g(x)=f(2-x)/(f(2-x)+f(x-1))$; this function is smooth, since the denomentaor is always positive
(one term is 0 only for $x\geq 2$ and the other is zero only for $x\leq 1$), takes values
between 0 and 1, is one precisely when $f(x-1)=0$, i.e., $x\leq 1$, and is 0 precisely when 
$f(2-x)=0$, i.e., $x\geq 2$. Then the function $G:\bbr^n\rightarrow \bbr$ defined by
$G(y)=g(||y-x_0||^2)$ is smooth (it's the composition of smooth functions), is
1 on $B(x_0,1)$ and has support contained in $B(x_0,2)$. Taking our charts $h_i$
built above, the function $h_i\circ G$ extends (by taking the value 0) to a smooth 
function $f_i:M\rightarrow \bbr$ which is 1 on 
$h_i^{-1}(B(x_i\,1))$ and has support in $h_i^{-1}(B(x_i\,2))$. Since every
point has a neighborhood which lies in only finitely many of the $h_i^{-1}(B(x_i\,2))$,
the sum $F=\sum f_i$ is locally a finite sum and so is a smooth function on $M$.
Since the $h_i^{-1}(B(x_i\,1))$ cover $M$, it is everywhere non-zero. So each 
of the functions $F_i=f_i/F$ is smooth, their supports = the supports of the $f_i$
are locally finite, and their sum (which is locally a finite sum) is $1$. that is,
they form a smooth partition of unity subordinate to the cover
$h_i^{-1}(B(x_i\,2))$, which is a refinement of our original cover $\Cal O$. So they
form a smooth partition of unity subordinqate to $\Cal O$.

\msk

{\bf Density of smooth functions:} Now that we have a partition of unity, what do we do with it?
One immediate application of partitions of unity is: for every continuous function $f:M\rightarrow \bbr$
and $\epsilon > 0$, there is a smooth function $g:M\rightarrow \bbr$ with $|f(x)-g(x)|< \epsilon$ 
for all $x\in M$. The proof consists of looking at the open cover $\{f^{-1}(f(x)-\epsilon,f(x)+\epsilon)\}$,
and choose a partition of unity $g_i$ subordinate to this cover. For each $g_i$ pick a point $x_i$ with 
supp$(g_i)\subseteq f^{-1}(f(x_i)-\epsilon,f(x_i)+\epsilon)$. Then the function $g(y)=\sum f(x_i)g_i(y)$ is smooth
(since the $f(x_i)$ are constants, so this is a locally finite sum of smooth functions), and 
$|f(y)-g(y)|=|\sum g_i(y)(f(y)-f(x_i))|\leq \sum g_i(y)|f(y)-f(x_i)| < \sum g_i(y) \epsilon = \epsilon$,
since either $g_i(y)=0$, or $g_i(y)>0$, so $y\in f^{-1}(f(x_i)-\epsilon,f(x_i)+\epsilon)$, so 
$f(y)\in (f(x_i)-\epsilon,f(x_i)+\epsilon)$, so $|f(y)-f(x_i)|<\epsilon$.

\ssk

Partitions of unity can also be used to build {\it bump functions};
given a closed set $C$ of $M^n$ and an open set $U$ with $C\subseteq U$, we can build a smooth
function $f:M\rightarrow \bbr$ which is $1$ on $C$ and has support contained in $U$. The idea is simply to take the 
open cover $\{U,M\setminus C\}$ and build a smooth partition of unity $\psi_i,\phi_j$ subordinate to it.
with supp$(\psi_i)\subseteq U$ and supp$(\phi_j)\subseteq   M\setminus C$ for every $i$ and $j$.
Then set $\psi=\sum_i\psi_i$ and $\phi=\sum_j\phi_j$; by local finiteness, both are smooth functions.
Since $\psi(x)+\phi(x)=1$ for all $x$ and $\phi(x)=0$ outside of $M\setminus C$ (since all summands are), i.e., 
for $x\in C$,
we have $\psi(x)=1$ for $x\in C$; since $\psi(x)=0$ outside of $U$, we have
$\psi(x)=0$ for $x\notin U$, as desired. (This last statement does not quite say that supp$(\psi)\subseteq U$;
but this can be remedied by using a slightly smaller open set $V$ in place of $U$, with 
$C\subseteq V\subseteq \overline{V}\subseteq U$, which exists by the normality of $M$.)

\msk

{\bf Embedding in $\bbr^n$:} Another immediate application (of our proof, really) is that if 
$M^n$ is a smooth manifold, then 
there is a smooth
embedding (that is, a topological embedding that is a smooth map) of $M$ into 
$\bbr^n$ for some $N$. Right now we will prove this for compact
$M$; later we will show it for all $M$. To build the embedding, cover $M$ by finitely many 
coordinate charts $(h_i,U_i)$,
$i=1,\ldots ,k$, so that $B(x_i,2)\subseteq h_i(U_i)$ and the $h_i^{-1}(B(x_i,1))$ cover $M$.
Then taking a smooth bump function $g_i$ that is 1 on $h_i^{-1}(B(x_i,1))$ and supported on $U_i$, we can build 
the smooth functions $f_i=g_i\cdot h_i:M\rightarrow \bbr^n$; Then the smooth function
$F:M\rightarrow \bbr^{nk}=(\bbr^n)^k$ given by $F(x)=(f_1(x),\ldots ,f_k(x))$ is 1-to-1; 
mapping from a compact space to a Hausdorff one, it is a homeomorphism onto its image.
In a sense which we will eventually make precise, the smooth structure on $M$ is induced
from the map $F$ and the smooth structure on $\bbr^{nk}$, making this a smooth embedding.

\msk

{\bf Tangent vectors:} In multivariable calculus, a prominent place is taken up by vectors, 
underlying many constructions and techniques. Tangent vectors, directional
derivatives, gradients, and vector fields appear throughout the subject. Our next task is to 
introduce this technology into smooth manifolds.
It turns out there are about as many ways to approach the concept of tangent vector as there were
early researchers in the field. But in a way which we will make fairly precise, all are really
the same. We will introduce (at least) two of them, since they both have their own advantages
in different situations. 

\ssk

In $\bbr^n$, the notion of a direction is expressed by a vector $v$ based at a point. This leads
to the notion of the directional derivative $D_vf$; the rate of change of $f$ in the direction of
$v$. One way to approach (tangent) vectors for manifolds is to borrow directional derivatives,
making a defnition out of the properties which they have in multivariable calculus. This
will be one point of view we will take. 



{\bf Velocity vectors:} Borrowing vectors directly will work (with a little effort); but we can
reformulate them more directly, in terms of things that we can borrow more directly, namely 
smooth functions. Specifically,
in $\bbr^n$ a vector $v$ at $x$ describes a direction by way of the curve $\gamma(t) = 
x+tv$; $v$ is the derivative of $\gamma$ at $t=0$. We can translate this picture to a smooth
manifold using charts; given a chart $(h,U)$ around $x$, $\eta=h^{-1}\circ\gamma$, defined on 
a small interval around $0$, is a smooth curve $\eta:(-\epsilon,\epsilon)\rightarrow M$. It's
derivative at $0$, using the coordinate chart $h$, is $v$. But of course this result is dependent
upon the chart chosen, both to define it and to evaluate it. But the idea of a smooth
curve {\it isn't}. So instead we make our definition based on them. A tangent vector at a point $x$
will ``be' the derivative, at $t=0$, of a smooth curve with value $x$ at $t=0$. But different curves 
can have the same derivative, so we need to introduce an equivalence relation to make a formal definition. 

\ssk

A tangent vector at $x\in M$ is an equivalence class of smooth curves
$\gamma:(-\epsilon,\epsilon)\rightarrow M$ with $\gamma(0)=x$. Two such curves $\gamma,\eta$
are equivalent if for some chart $(h,U)$ about $x$ we have $(h\circ\gamma)^\prime(0)=(h\circ\eta)^\prime(0)$ .

\ssk 

Informally, we tend to think of this as saying that two curves are equivalent if they have the
same velocity vector at $t=0$ ! Note that the equivalence is independent of coordinate chart
chosen; if $(k,V)$ is another chart (for convenience, let us suppose that $h(x)=k(x)=0$),
then $(k\circ\gamma)^\prime(0)=[D(k\circ h^{-1})(h(x))](h\circ\eta)^\prime(0)$ 
(where this is matrix multiplication),
so $(h\circ\gamma)^\prime(0)=(h\circ\eta)^\prime(0)$ implies
$(k\circ\gamma)^\prime(0)=(k\circ\eta)^\prime(0)$.

\msk

But now we see how we {\it ought to} to relate tangent vectors from the point of view of different charts;
we use the total derivative map $D(k\circ h^{-1})(h(x))$. And we can use this to get rid of the smooth curves!
Writing $k\circ\gamma)^\prime(0)=w$ and $h\circ\eta)^\prime(0)=v$, what is important is that
$w=D(k\circ h^{-1})(h(x))v$, which needs no mention of curves at all. So we can define
a tangent vector at a point $x\in M$ as an equivalence class of triples $(x,h,v)$, where
$h$ is a chart whose domain contains $x$, and $v$ is a vector based at $h(x)\in \bbr^n$.
Another tangent vector (y,k,w) is equivalent if
$y=x$ and $w=k\circ\gamma)^\prime(0)=w$. We will let $[h,v]_x$ denote the equivalence class.
This construction illustrates a basic theme that runs throughout the development of 
differential topology: To introduce an object from calculus, all we need to 
do, really, is figure out how the object would transform when we change our point of view by using
a different chart around at point, and incorporate that into the definition, in the form of an
equivalence relation. The point, really, is that so long as we are working locally, we can essentially
pretend that it {\it is} the familiar object from calculus; it is only when we start looking at how
the object behaves as we wander around the manifold that we need to remember how they transform
as we need to keep changing coordinate charts, as our point of view keeps shifting.

The set of tangent vectors $[h,v]_x$ at a point form a vector space, the {\it tangent space},
$TM_x$ or $T_xM$, at the point $x$. The union $\bigcup T_xM=TM$ is the tangent space of $M$. We
could keep talking about this, exploring it various properties from this point of view, but let us
back up and start again using the directional derivative point of view.

\msk

{\bf Derivations:} Given a vector $v$ based at $z\in \bbr^n$, it allows us to define the directional
derivative $(D_vf)(x)$ of any differentiable function whose domain contains a neighborhood about $z$.
That is, we have an operator $D_v$ from smooth functions to $\bbr$. This operator is linear, and
satisfies a Leibnitz rule: $D_v(fg)=gD_vf+fD_vg$ (this last is because $D_v$ is `really'
the gradient dotted with $v$, so it is a linear combination of the partial derivatives, and
the partial derivatives satisfy the Leibnitz rule). Such an operator is called a {\it derivation}.
But such a concept makes sense anywhere that the notion of `differentiable function' makes sense,
e.g., on a smooth manifold. Since $D_v$ takes too long to write, and $D_v$ is really {\it replacing} 
the notion of the vector $v$, we will write $D_v=X$ in general.

\ssk

For $a\in M^n$ a smooth manifold, a {\it derivation at $a$} is a map $X:C^\infty(M)\rightarrow \bbr$
satisfying $X(\alpha f+\beta g) = \alpha X(f)+\beta X(g)$ and 
$X(fg)=f(a)X(g)+g(a)X(f)$, for $\alpha,\beta\in \bbr$ and $f,g\in C^\infty(M)$.

\ssk

The set of all derivations at $a$ will be denoted $T_aM$. These will be our `tangent vectors' at $a$.
On the face of it, this definition is hopelessly abstract, but we can get a better handle on it by
outlining some of its basic properties.

\ssk

{\it Lemma:} If $c\in C^\infty(M)$ is constant, $c(x)=c$, then $X(c)=0$. If $f(a)=g(a)=0$, then $X(fg)=0$.
If $f=g$ on a neighborhood of $a$, then $X(f)=X(g)$.

\ssk

{\it Proof:} First, $X(1) = x(1\cdot 1) = 1\cdot X(1)+1\cdots X(1)=2\cdot X(1)$, so $X(1)=(2-1)X(1)=0$.
Then $X(c)=cX(1)=c\cdot 0=0$. For the second, $X(fg)=f(a)X(g)+g(a)X(f)=0+0=0$.
And finally, choose a small chart $(h,U)$ around $a$, with domain contained in the neighborhood
on which $f$ and $g$ agree, and build a bump function $B$ supported on $U$
and equal to $1$ on the closure of a small ball $h^{-1}(B(b,\epsilon))$. Then
$fB=gB$ on all of $M$; inside of $U$ they agree by hypothesis, and outside of $U$ they are both $0$.
So $X(fB)=X(gB)$; but then 
$0=X(fB)-X(gB) = (f(a)X(B)+B(a)X(f))- (g(a)X(B)+B(a)X(g)) = g(a)X(B)+X(f)-g(a)X(B)-X(g)=X(f)-X(g)$,
so $X(f)=X(g)$.

\ssk

So the derivation $X$ is really `local'; it depends only on the values of $f$ near $a$. Which would
indicate that we ought to be able to understand them better using charts! Which we will do. But first, 
a little more theory. A chart can be thought of as a $C^\infty$ map from a neighborhood in $M$ to the
standard smooth structure on $\bbr^n$. So understanding how derivations behave under smooth maps
will help us understand derivations.

\ssk

{\bf Pushforwards:} Given a smooth map $F:M^n\rightarrow N^m$ and $a\in M$, 
we can `push forward' a derivation $X$ at $a$ 
to a 
derivation at $F(a)$, which we will call $F_*(X)$; we define 
$F_*(X)(f)=X(f\circ F)$. It is a 
straighforward calculation, using the fact that $(f\cdot g)\circ F = (f\circ F)\cdot(g\circ F)$ that
$F_*(X)$ is a derivation at $F(a)$ [don't forget linearity!]. The following facts are also 
pretty straighforward:

\ssk

{\it Lemma:} $(F\circ G)_*=F_*\circ G_*$ . Id$_*$ = Id . If $F$ is a diffeomorphism, then 
$F_*$ is an isomorphism for every $a\in M$.

\ssk

With these, we can go explore derivations using charts, and get a better understanding of them.
First, because the definition of a derivation is really local, if $U\subseteq M$ is open 
and $a\in U$, then the inclusion map $i:U\rightarrow M$ induces an isomorphism
$i_*:T_aU\rightarrow T_aM$ ; choosing a bump function $g$ which is $1$ on  neighborhood
of $a$ and supported on $U$, we can extend any smooth function $f$ on $U$ to a function $gf$ on $M$
which equals $f$ on a neighborhood of $a$.
Then comparing a derivation $X$ on $U$ and the derivation $i_*X$ on $M$, 
we have $i_*X(gf)=X(gf\circ i)=X(f)$, since $gf\circ i$ and $f$ agree on a neighborhood of $a$.
So if $i_*X_1=i_*X_2$, then $X_1f=X_2f$ for every $f:U\ra \bbr$, so $X_1=X_2$ and $i_*$ is injective.
To show surjectivity, given $X\in T_aM$, define $Y\in T_aU$ by $Y(f)=X(gf)$. A computation shows that $Y$ is a 
derivation at $a$. Then for any $f\in C^\infty(M)$, $i_*(Y)(f)=Y(f\circ i) = X(g(f\circ i)) = X(f)$,
again, since $g(f\circ i)$ and $f$ gree near $a$. So $i_*Y=X$ and $i_*$ is onto. SO $i_*$ is an
isomorphism.

But now a chart $(h,U)$ is a diffeomorphism $U\ra \bbr^n$ for the standard smooth structure on
$\bbr^n$, so $T_aU$ is isomorphic to $T_{h(a)}\bbr^n$. So to understand the tangent space
at a point, we may assume that $M=\bbr^n$! But we can build a collection of derivations in
$\bbr^n$; the directional derivatives $D_v=\sum_i v^i(\del/\del x^i)$ for $v=(v^1,\ldots ,v^n)$.
The last piece of the puzzle is:

\ssk

{\it Lemma:} The map $I:v\mapsto D_v$ is an isomorphism.

\ssk

To prove it, look at the coordinate functions $f_j:x=(x^1,\ldots ,x^n)\mapsto x^j$ and note that
 $D_v(x^j)=\sum_i v^i(\del x^j/\del x^i)=v^j$, so $D_v=D_w$ implies $v=w$,
and $I$ is injective. For surjectivity, given a derivation $X$ on $\bbr^n$ at $a$,
let $v^i=X(f_i)$, and $v=(v^1,\ldots ,v^n)$. We show $X=D_v$; given $f\in C^\infty(\bbr^n)$, we
can expand $f$ as a power series centered at $a=(a^1,\ldots ,a^n)$. 

\ssk

\ctln{$\displaystyle f(x)=f(a)+\sum_i{{\del f}\over{\del x^i}}(a)(x^i-a^i) + \sum_i g_i(x)(x^i-a^i)$}

\ssk

\noindent where $g_i(a)=0$, by a result of advanced calculus. Since $f(a)$ is constant and
$g_i(x)$ and $x^i-a^i$ are both $0$ at $a$, $X(f)=\sum_i f_{x^i}(a)v^i=D_v(f)$, so $X=D_v$.
Finally, from calculus we know that $I$ is linear. So $I$ is an isomorphism.

\msk

The derivations $X_i=\del/\del x^i$ form a basis for $T_a\bbr^n$. Carrying these back to $M$ via 
a chart $h:U\ra\bbr^n$, or rather the map $h_*:T_aU\ra T_{h(a)}\bbr^n$. But to get back
to $M$, we use $(h^{-1})_*$;  this map carries the basis $X_i$ to
$(h^{-1})_*X_i$, where $((h^{-1})_*X_i)f=X_i(h^{-1}\circ f)=\del(h^{-1}\circ f)/\del x^i$.
Which should sound familiar! This is what we denoted $\del f/\del x^i$, where 
$h(y)=(x^1(y),\ldots x^n(y))$. So the derivatives with respect to the coordinate functions
of our chart $h$, $\del/\del x^i$, form a basis for $T_aM$. 

\ssk

The three approaches to the concept of a tangent vector can all be brought together by decribing
the basis vectors for $T_aM$ from each point of view. For derivations, they are the differentiation
operators $\del/\del x^i$ for the coordinate functions. For curves, they are the derivatives
at $a$ of the functions $t\mapsto h^{-1}(h(a)+t(0,\ldots ,1,\ldots ,0))$. For vectors, they
are the equivalence classes $[h,(0,\ldots ,1,\ldots ,0)]_a$. Each of these descriptions are
local, usng the chart $h$.

In particular, given a smooth curve $\gamma:(-\epsilon,\epsilon)\ra M$ with $\gamma(0)=a$,
the map $f\mapsto (f\circ \gamma)^\prime(0)$ is a derivation at $a$; this follows
from the fact that $(fg)\circ\gamma = (f\circ\gamma)(g\circ\gamma)$. Chasing this through
both descriptions will verify that this assignment is an isomorphism between our 
equivalence classes of curves and the space of derivations at $a$.

\msk

{\bf Computations in local coordinates:} Tangent vectors as derivations are defined globally, 
but are typically worked with locally. Given $a\in M$ and a chart $(h,U)$ around $a$, 
a derivation $X$ can be written $X=\sum_i v^i\del/\del x^i$ (evaluated at $h(a)$), 
where $h=(x^1,\ldots ,x^n)$.
Given a map $F:M^n\ra N^m$ we can express the pushforward in local coordinates: let 
$(k,V)$ be a chart around $b=F(a)$, with $k=(y^1,\ldots ,y^m)$. We know we can write 
$F_*X=\sum_j w^j\del/\del y^j$ for some $w^j$; the task is to compute $w^j$. But
$w^k=(\sum_j w^j\del/\del y^j)(y^k)$, since $\del y^k/\del y^j=\delta_{kj}$.
So in order to compute $w^j$ we need to compute 
$w^j=F_*X(y^j)= X(y^j\circ F) = \sum_i v^i\del(y^j\circ F)/\del x^i$.
The constants $\del(y^j\circ F)/\del x^i$ form the matrix a partial derivative of $F$, 
in local coordinates, and so $\sum_i v^i\del/del x^i$ is carried to 
$\sum_j[\sum_i v^i\del(y^k\circ F)/\del x^i]\del/del y^j$. 

In particular, if we set $F=$Id = the identity function, we can recover a change of
variables formula for tangent vectors: given two charts $h=(x^1,\ldots ,x^n)$ and
$k=(y^1,\ldots ,y^n)$ about $a\in M$, we have 
$\del/\del x^i = \sum_j(\del y^k/\del x^i)\del/del y^j$, which is, of course, the
exact same change of variables formula we had for tangent vectors as smooth
curves and as vectors. This formula extends to $T_aM$ by linearity. This formula
allows us to translate computations when we switch perspectives by using a 
different chart.

\ssk

As an example, let us examine the tangent vectors to $S^2$ using a variety of
standard charts on $S^2$. We have the standard projection coordinates 
$h_1:(x^1,x^2,x^3)\mapsto (x^1,x^2)$, etc., 
with inverse $(x^1,x^2)\mapsto (x^1,x^2,\sqrt{(1-(x^1)^2-(x^2)^2})$.
There are the stereographic coordinates
$k_1:(y^1,y^2,y^3)\mapsto (y^1,y^2)/(1-y^3)$ , etc.. ,
with inverse $(y^1,y^2)\mapsto (2y^1,2y^2,|y|^2-1)/(|y|^2+1)$.
We also have spherical coordinates, 
which we are all probably more familiar writing the inverse for:
$\ell_1^{-1}:(\theta,\varphi)\mapsto (\cos\theta \sin\varphi, \sin\theta \sin\varphi,\cos\varphi)$.
The inverse of the inverse is 
$\ell_1:(z^1,z^2,z^3)\mapsto(\arctan(z^2/z^1),\arccos(z^3))$ .
So, for example, on the upper hemisphere, we can compute the change of coordinates
formula from sphereical to projection coordinates as the total derivative 
of the map $(\theta,\varphi)\mapsto (\cos\theta \sin\varphi,\sin\theta \sin\varphi)$,
which is the matrix $(-sin\theta \sin\varphi,\cos\theta \sin\varphi;\cos\theta \cos\varphi,\sin\theta \cos\varphi)$.

\msk

{\bf The tangent space:} In any of its manifestations, we can assemble the tangent spaces
$T_aM$ at points $a$ into a single tangent space $TM=\bigcup_aT_aM$. But the change of 
variable formula above can be turned into a prescription for putting a topology, and
a smooth structure, on $M$. $TM$ is locally homeomorphic to $\bbr^n\times \bbr^n=\bbr^{2n}$,
by charts $H:TU\ra \bbr^{2n}$, induced by a chart $(h,U)$, $h=(x^1,\ldots ,x^n)$ for $M$, where
$H(X_a)=(h(a),(X_a(x^1),\ldots ,X_a(x^n))$. Given a second chart $(k,V)$ , $k=(y^1,\ldots ,y^n)$
for $M$, the transition function for $TM$, using the change of variables formula, is given by
$H\circ K^{-1}(b,(v^1,\ldots ,v^n))=
(h\circ k^{-1}(b),(\sum_i v^i(\del x^1/\del y^i),\ldots ,\sum_iv^i(\del x^n/\del y^i)))$.
This function is smooth, since in the first $n$ coordinates it is the transition function
for $M$, and in the second $n$ coordinates it is essentially built out of the partial
derivatives of the coordinate functions, which are also smooth. The topology on $TM$
is generated from these charts; a basis consists of images under the $H^{-1}$ of a basis
of open sets on $\bbr^{2n}$. Since a countable number of charts cover $M$ and each of
the charts provide a countable collection of sets to add to the basis, we have second
countability. Hausdorffness proceeds similarly (two cases: in the same chart or never in
the same chart). The natural map $p:TM\ra M$ sending a derivation at $a$ to $a$ is smooth.


\msk

{\bf Vector fields:} The tangent bundle gives us the framework to introduce another standard
concept from advanced calculus. A vector field is a choice of vector at every point in a space.
From the point of view of $TM$, a (tangent) vector field is a choice of element of $T_aM$
for every $a\in M$. Put differently, a vector field $X$ is a map $X:M\ra TM$ so that
$X(a)\in T_aM$ for every $a\in M$; i.e., $p\circ X:M\ra TM\ra M$ is the identity map.
Generally, for a vector bundle $p:E\ra M$, a map $s:M\ra E$ with $p\circ s=\text{Id}_M$
is called a {\it section} of the bundle. So a vector field on $M$ is a section of the tangent
bundle. The vector field is {\it smooth} if the section is a smooth map. The set of all
smooth vector fields on $M$ is denoted ${\Cal T}(M)$.

Writing things in local coordinates $(h,U)$, a vector field can be expressed as 
$X=\sum_i v^i\del/\del x^i$, where the $v^i$ are functions from $U$ to $\bbr$. 
$X$ is smooth \lra\ the functions $v^i$ are smooth; this follows from the construction
of the smooth structure on $TM$. 
Given a smooth vector field $X$ and a smooth function $f:M\ra \bbr$ the assignment $a\mapsto
X_af$ is a function. Writing things in local coordinates, $Xf=\sum v^i\del f/\del x^i$ is a smooth
function.
This point of view actually provides another characterization of smoothness:
$X$ is smooth \lra\ $Xf$ is smooth for every smooth map $f:M\ra \bbr$. This is because
in local coordinates the $v^i$ can be recovered as $Xx^i$ (or rather, the coordinate
function $x^i$ multiplied by a bump function for the chart), and $x^i$ is smooth, 
so $Xx^i=v^i$ is smooth and $X$ is smooth.

The fact that $Xf$ is a smooth function for smooth $f$ and smooth vector field $X$ means that
we can use $Xf$ as the function to feed another vector field $Y$, allowing us to 
define $YX$ as $(YX)(f)=Y(Xf)$. But $YX$ is not a vector field; it fails to be a
derivtion at a point. We can compute

$YX(fg)=Y(f(Xg)+g(Xf))=Y(f(Xg))+Y(g(Xf))=f(YX)g+(Yf)(Xg)+g(YX)f+(Yg)(Xf)=[f(YX)g+g(YX)f]+(Yf)(Xg)+(Yg)(Xf)$

\noindent and we have no reason to believe that the last two terms will cancel one another.
But! Those last two terms are symmetric in $X$ and $Y$, and $YX(fg)$ isn't. So if we compute
$XY(fg)$, we will get the same two extra terms. So if we subtract these two expressions, they will
cancel. That is, 
$(XY-YX)(fg)=f(XY-YX)g+g(XY-YX)f$, so $XY-YX$ is a derivation (a quick check shows that it is 
linear), and therefore defines a vector field, called the {\it Lie bracket} 
$[X,Y]=XY-YX$ of $X$ and $Y$. A direct computation in local coordinates reveals that
$[\sum_i v^i\del/\del x^i,\sum_i w^i\del/\del x^i]=
\sum_i(\sum_j v^j(\del w^i/\del x^j)-w^j(\del v^i/\del x^j))\del/\del x^i$ . So the Lie bracket of two 
smooth vector fields is a smooth vector field.

\msk

The Lie bracket satisfies several useful properties:

(a) it is $\bbr$-linear in each entry: $[aX+bY,Z] = a[X,Z]+b[Y,Z]$ for $a,b\in \bbr$, etc.

(b) it is antisymmetric: $[X,Y]=-[Y,X]$

(c) it satisfies the {\it Jacobi identity}: $[X,[Y,Z]]+[Y,[Z,X]]+[Z,[X,Y]]=0$ (the $0$ vector field).

Each can be verified by evaluating each side on a smooth function $f$, checking that we get the same answer.
A natural question to ask is "what does the Lie bracket really measure?". On the face of it, it measures
the extent to which two vector feilds fail to commute. In fact, the fact that our coordinate vetor fields
$\del/\del x^i$ do commute ("mixed partials are equal") has a converse; If $X_1,\ldots X_k$ are vector
fields defined on some open set $V$ so that the $X_i(a)\in T_aU$ are linearly independent at every $a$,
and $[X_i,X_j]=0$ on $V$ for every $i,j$, then around every point there is a coordinate system
$(h,U)$ so that in these local coordinates $X_i=\del/\del x_i$ for $i=1,\ldots ,k$. [We may
prove this at some future point.]

But what is the significance
of the direction that $[X,Y]$ points, when it is non-zero? To answer this, we need to introduce 
integral curves. And to do \u{that} we need to discuss pushforwards of vector fields.

\msk

{\bf Pushforwards and ${\Cal F}$-relatedness:} We have seen that a smooth map $f:M\ra N$
induces a map $f_*:TM\ra TN$ which is linear on each $T_aM$. So if we wish to push a
vector field $X$ on $M$ to a vector field on $N$, the natural thing to do would be so set
$(f_*X)(b) = f_*(X_a)$ where $f(a)=b$. There are, of course, two problems with this;
$f$ might not be onto, so there is no $a$ in the preimage of $b$, and $f$ might not
 be 1-to-1, so there might be more than one $a$ in the preimage, and the various
values of $f_*(X_a)\in T_bN$ might not agree. The concept of ${\Cal F}$-relatedness
essentially declares that the second problem does not occur: two vector fields
$X$ on $M$ and $Y$ on $N$ are ${\Cal F}$-related if $f_*(X_a)=Y_{f(a)}$ for all $a\in M$.
Note that since a vector field is determined by its values on smooth (e.g., coordinate) functions,
whether or not two vector fields are ${\Cal F}$-related can also be determined
by testing values on functions: $X$ and $Y$ are ${\Cal F}$-related \lra\ $X(g\circ f)=Y(g)\circ f$
for every smooth map $g:N\ra \bbr$.
Given a vector field $X$ on $M$, there is of course no reason to expect there to be
a vector field on $N$ ${\Cal F}$-related to $X$. Nor given $Y$ on $N$ should
there be a vector field on $M$ ${\Cal F}$-related to $Y$. (Think: the constant function $f$.)
But in one special case, which we use again and again, we can expect such good things:

\ssk

If $f:M\ra N$ is a diffeomorphism, then for every $X\in {\Cal T}(M)$ there is a unique 
$Y\in {\Cal T}(N)$ ${\Cal F}$-related to $X$. This is mostly a matter of figuring out
what $Y$ \u{has} to be; we want $f_*(X_a)=Y_{f(a)}$, so define
$Y_b=f_*(X_{f^{-1}(b)})$, which is well-defined since $f$ has an inverse. Uniqueness of $Y$
is immediate; plug $b=f(a)$ (so $a=f^{-1}(b)$) into the definition of ${\Cal F}$-relatedness.
All that is left is to show that $Y$ is a smooth vector field. This can be done using the
local coordinates $h\circ F^{-1}$ for some coordinate chart $h$ on $M$ about $a$; then 
$Y$ has the exact same local formula as $X$ does. 

\ssk

The point to this really, is that we want to be able to think of (the restriction of) 
a vector field on $M$ as ``really'' being a vector field on $\bbr^n$, using a local
coordinate chart. Since a chart $h:U\ra \bbr^n$ is a diffeomorphism onto its 
image, we can use pushforwards to work with our vector fields as if they were in $\bbr^n$.
This is really just a fancy way of saying that we are working in local coordinates.
so you should mostly treat this as a warning that in general there is no such thing
as the pushforward of a vector field?


\msk

{\bf Integral curves:} Given a smooth curve $\gamma:I\ra M$, the derivative $\gamma^\prime(t)$
can be defined as $\gamma_*(d/dt)\in T_{\gamma(t)}M$; this is how our notion of velocity vector
for a curve translates into the language of derivations. $\gamma$ is an {\it integral curve}
for a tangent vector field $X$ on $M$ if $\gamma^\prime(t)=X(\gamma(t))$ for all
$t$ in the domain of $\gamma$. It is a consequence of the fundamental existence and uniqueness 
theorem for solutions to ODEs that for every smooth vector field $X$ and $a\in M$ there is
an integral curve $\gamma$ for $X$ with $\gamma(0)=a$; any two such integral curves agree
on a neighborhood of $0$. The idea is to choose a chart $(h,U)$ about $a$; using the fact 
that $TU=TM|_U\cong T\bbr^n$ we can translate the problem of finding an integral curve in $U$
to finding integral curves for a vector field $Y$ on $\bbr^n$; set $Y_{h(x)}=h_*(X_x)\in T_{h(x)}\bbr^n$.
This gives us a vector field on $\bbr^n$, which, in the standard coordinates, is just a collection of 
smooth functions $Y(y)=(f_1(y),\ldots ,f_n(y))$. We find an integral curve $\eta=(\eta_1,\ldots ,\eta_n)$ satisfying 
$\eta^\prime(t)=Y(\eta(t)$ by solving each of the differential equations $\eta_i^\prime(t)=f_i(\eta_i(t)$,
which, since the $f_i$ are smooth, each have a unique solution with $\eta_i(0)=x^i(a)$.
Pushing this curve back to $M$ using $h^{-1}$ gives an integral curve to $X$ on $M$.
Uniqueness implies that any solution we find using another coordinate chart will agree with this one
(push it over with the transition function and it will give ``another'' solution in our original
coordinate system; uniqueness implies that they are actually the same). 

\ssk


Given two vector fields $X,Y$, we therefore have two sets of integral curves, $\gamma_x$ tangent to $X$ 
and $\eta_x$ tangent to $Y$. If we choose $\epsilon$ small enough, we can, starting with $a\in M$,
follow the integral curve to $X$ through $a$ from $t=0$ to $t=\epsilon$ arriving at $b\in M$, then 
follow $\eta_b$ from $b=\eta_b(0)$ to $c=\eta_b(\epsilon)$, then $\gamma_c$ to $d=\gamma_c(-\epsilon)$,
then $eta_d$ to $e=\eta_d(-\epsilon)$. Think of $e=\theta(\epsilon)$ as a curve. This curve, it
turns out, is smooth, $\theta^|prime(0)=0$, and $\theta^{\prime\prime}(0)=2[X,Y]_a$ ! 
So $[X,Y]$ points in the direction that, following the integral curves to $X$ and $Y$ around a 
``square'', we infinitesimally fail to close up.

\msk

{\bf Vector bundles:} 
The tangent space is our first example of a {\it vector bundle}. The idea behind a $k$-bundle $E$ over
a space $M$ is that we have a $k$-dimensional vector space ``over'' each point of $M$, which locally
fit together as a Cartesian product. More precisely, 
we have a map $p:E\ra M$ so that for every $a\in M$ there is a neighborhood $U$ of $a$
for which $p^{-1}(U)\cong U\times \bbr^k$ via a map $h_U:p^{-1}(U)\ra U\times \bbr^k$, so that
the diagram 

\ssk

\ctln{$\displaystyle \CD
p^{-1}(U)  @>h_U>> U\times\bbr^k\\
@VpVV   @V\text{pr}_1VV\\
U @>\text{Id}>> U
\endCD$}

\ssk

\noindent commutes. Moreover, for each $x\in M$, the {\it fiber} $p^{-1}(x)=E_x$ has the structure of
a vector space of dimension $k$ so that, for each $U$ with $x\in U$, the restriction
of $h_U$ maps $E_x$ to $\{x\}\times \bbr^k$ by a linear isomorphism.

That is, locally the bundle map looks like the projection
onto the first coordinate of a product with the vector space $\bbr^k$.
This is precisely what we have for the tangent space. The basic idea is
that each point of $M$ has a vector space $\bbr^k$ attached to it, so that this assignment is
`locally trivial' in the sense of the commutative diagram. In the case of the tangent space
(which we will now start calling the {\it tangent bundle}), our coordinate charts for TM are the 
local trivializations we need: $H:TU\ra h(U)\times \bbr^n$ was given by
$H(a,X_a)=(h(a),(X_a(X^1),\ldots ,X_a(x^n))$, where $h=(x^1,\ldots ,x^n)$.

The tangent space of a smooth manifold
is just one such family of examples of vector bundles. 
The {\it trivial bundle}
$M\times \bbr^k$, with projection map $\text{pr}_1$, is another example. 
It is called trivial because it has a {\it global} trivialization. The (open)
M\"obius band is the total space of a (non-trivial) $1$-bundle, or line bundle, over the circle.

The tangent bundle will not be the only `bundle' over a smooth manifold
$M$ that we will find ourselves interested in. There will be many other linear spaces that we
will wish to assign to each point $a\in M$, and assemble into a bundle. So it will benefit
us to discover some general facts about these objects. First, for any subset
$A\subseteq B$, $E_A=p^{-1}(A)$ and the restriction map $p|_A:E_A\ra A$ for a $k$-bundle,
as well, the restrictions of the local trivializations for $E$ demonstrate this.

A vector bundle $p:E\ra M$ is {\it smooth} if $E$ and $M$ are smooth manifolds, $p$
is a smooth map, and the bundle admits smooth local trivializations. We will, of course, 
be interested primarily in smooth bundles. Smooth bundles share several features in common
with the tangent bundle. For the tangent space, the transition functions between two
local trivializations had the form 
$t:h(U\cap V)\times \bbr^n\ra k(U\cap V)\times \bbr^n$ is $(k\circ h^{-1},D(k\circ h^{-1})$.
As a tangent bundle, we supress the first function and think of $TU$ as diffeomorphic to
$U\times \bbr^n$ instead of $h(U)\times \bbr^n\subseteq \bbr^{2n}$. So the map on the first coordinate
is the identity.
In general, for a smooth vector bundle, the transition functions are smooth maps
$(U\cap V)\times \bbr^k\ra(U\cap V)\times \bbr^k$ of the form $t(a,v)=(a,\tau_a(v))$
where $\tau_a\in GL(n,\bbr)$. The map $a\mapsto \tau_a$ is a smooth map from 
$U\cap V$ to $GL(n,\bbr)$, since the $(i,j)-th$ entry of this map is given by
$a\mapsto$pr$_i \tau_a(\del/\del x^j)$, which is the composition of smooth functions.

\msk

A {\it section} of a vector bundle $p:E\ra M$ is a function $s:M\ra E$ satisfying $p\circ s=Id$.
That is, it is a choice of vector at $a$ for every $a\in M$. A continuous section is a 
continuous such function; a smooth section is a smooth such function. All bundles have 
continuous sections; choosing the $0$-vector at each point we have the $0$-section. If 
the bundle is smooth, so is this section. Not all bundles have a {\it nowhere zero section}
$s:M\ra E$ with $s(p)\neq 0$ for all $p$; the M\"obius band, thought of as a line bundle
over the circle, has no such section. Proof: if it did, it would be the trivial bundle
(see below: global sections), but it isn't (see below: orientations!). 

This statement foreshadows the fact that
trivial bundles can be detected using sections. If $p:E\ra M$ is a trivial $k$-bundle, then 
there is a fiber-preserving homeomorphism $H:E\ra M\times \bbr^k$. If we let $e^i$ represent
the $i$-th coordinate vector, with $1$ in the $i$-th coordinate and $0$'s elsewhere, then 
$X_i:x\mapsto h^{-1}(x,e^i)$ is a section of the bundle $E$, and for every $p\in M$
$x_1(x),\ldots,X_k(x)$ form a basis for the vector space $p^{-1}(x)=E_x$. Such a collection
of sections is called a {\it global frame} for the bundle (as in ``frame of reference for
doing computations''?). Because vector bundles are locally trivial, a similar construction
will build {\it local frames} for us. Trivial bundles therefore have global frames; but
the converse is also true: a global frame provides a trivialization of the bundle, by
defining $H:E\ra M\times \bbr^k$ by $H(z)=(p(z),(v^1,\ldots ,v^k))$, where
$z=\sum_i v^iX_i(p(z))$. This is well-defined since the $X_i(p(z))$ form a basis for
$p^{-1}(p(z))$. Showing it is a bijection is straighforward, and that it is continuous
follows from the local triviality of the bundle. The inverse is continuous since
the sections $X_i$ are. If the bundle is smooth, the same argument establishes that the
maps are smooth. A smooth manifold $M^n$ is said to be {\it parallelizable} if its tangent bundle is 
fiber-preserving diffeomorphic to the trivial $n$-plane bundle. by the above, this is equivalent 
to the existence of $n$ vector fields which are linearly independent at each point.

\ssk

It turns out that there are a lot more parallelizable manifolds than we have any right to expect.
For example, all Lie groups are parallelizable. A Lie group is a group which is also a smooth
manifold, such that the multiplication snf inversion maps are smooth. As exmples, the familiar
linear groups, $GL(n,\bbr),O(n),SO(n),U(n)$, etc, are Lie groups. Building vector fields to
demonstrate the triviality of the tangent bundle is not too tough; you take your favorite
basis for the tangent space at the identity, and then, using the map $g:x\mapsto gx$,
we define vector fields by the map $g\mapsto g_*(X_e)$ for our basis vectors $X_e$ at $e$.
The fact that $g$ is a diffeomorphism says that we get a basis at each point $g\in G$, and a 
little work shows that the vector fields that we have built are smooth.

\msk

{\bf Bundle maps:} Given a smooth map $f:M\ra N$, we have seen how to construct a smooth
map $f_*:TM\ra TN$ by pushing forward tangent vectors. Now that $TM$ and $TN$ have
more structure - they are vector bundles - we can see that $f_*$ also has more
structure; it is a {\it bundle map}. In general, a bundle map between to vector bundles
$p:P\ra M$ and $q:Q\ra N$ is a pair of maps $f:M\ra N$ and $F:P\ra Q$ so that 
$F$ {\it covers} $f$, that is, $q\circ F = f\circ p$ (so $F$ sends
fibers $P_x$ to fibers $Q_{f(x)}$), and $F$ restricts to a linear
map on fibers $F:P_x\ra Q_{f(x)}$. A bundle map is continuous or smooth if both maps are.
A bundle isomorphism is a bundle map $f,F$ where $f$ is an isomorphism (homeo- or diffeo-),
and $F$ is an isomorphism on each fiber. A global trivialization $E\ra M\times \bbr^k$
is therefore ``just'' a bundle isomorphism from a bundle to the trivial bundle.
If $M=N$ and $f=$Id, then $F$ is called a {\it bundle map over $M$}.

Once you have maps, you of course have the notion of two objects being the ``same'':
A bundle isomorphism is a bundle map which is a homeomorphism/diffeomorphism
on the bases spaces and an isomorphism on every fiber. So saying, for example, that
a bundle is trivial really means that it is bundle isomorphic to the trivial 
bundle over the same base space. 

\msk

{\bf Orientations:} Perhaps one of the most persistent properties of bundles (and
manifolds) that one comes across is {\it orientability}. It is also often a rather
elusive concept to pin down. (Consequently, there are a large number of different, though
functionally equivalent, ways to define it; not unlike tangent vectors...) We define
orientability for bundles over general topological spaces; a smooth manifold $M$
is then called orientable if its tangent bundle is orientable. 

The basic idea is that a bundle $p:E\ra B$ is orientable if you can assign an
``orientation'' to each fiber $p^{-1}(a)$ which are compatible with a collection of local 
trivializations which cover $E$. An orientation of a vector space $V$ of dimension $n$ 
is a generalization of the 
``right-hand rule'' that we learn in calculus, except we don't discriminate 
against left-handed people; recall that a {\it frame} is any ordered basis ${\Cal B}=(e_1,\ldots ,e_n)$
for $V$. The standard frame for $\bbr^n$, for example, would be the coordinate
axis vectors in their natural order. Any pair of bases defines an isomorphism
$\varphi:V\ra V$ which takes one ordered basis ${\Cal B}$ to the other ${\Cal B}^\prime$
(and extends linearly); writing this as a matrix (using ${\Cal B}$, say, in both domain and
range), we essentially get the change of basis matrix $M$, expressing the ${\Cal B}^\prime$ in terms
of ${\Cal B}$. This matrix is non-singular, since both ${\Cal B}$ and ${\Cal B}^\prime$
are bases, and so has non-zero determinant. We say that ${\Cal B}$ and ${\Cal B}^\prime$ determine the
{\it same orientation} on $V$ if det$(M)>0$; since det$(MN)$=det$(M)$det$(N)$, ``determine the same
orientation'' is an equivalence relation on ordered bases. An equivalence class is called an
{\it orientation} on $V$; there are two of them. Given a frame $\Cal B$ representing an orientation on 
$V$ and an isomorphism $h:V\ra W$, there is an induced orientation on $W$, with representative
$h({\Cal B})=(h(v_1),\ldots h(v_n))$, so that $h$ carries the orientation on $V$ 
to the orientation on $W$.

\ssk

A bundle $p:E\ra B$ is {\it orientable} if every fiber $p^{-1}(a)$ can be given 
an orientation so that there is an open cover $\Cal O$ of $B$ and
a collection of local trivializations $h_U:p^{-1}(U)\ra U\times \bbr^n$ so that 
for every $U$ and every $a,b\in U$, the induced orientations on $h(a)\times \bbr^n$
and $h(b)\times \bbr^n$ (by translation in the $U$-direction) are the same. 
Note that, logically, the orientations of the fibers
comes first! It is in fact the case that if some cover ${\Cal O}$ of a path-connected space $B$ 
establishes that our bundle is orientable, then any cover ${\Cal O}^\prime$ does; choosing two points in
an element $U^\prime\in {\Cal O}^\prime$, a path between them, and a finite open cover of the 
path by elements $U_i$ of ${\Cal O}$. Then we can compare the trivializations given by the $U_i$
and $U^\prime$; along the path we see a continuous family of linear isomorphisms (from $U_i\times \bbr^n$
to $U^\prime\times\bbr^n$); applying the determinant we get a continuously changing family of
non-zero numbers. They therefore all have the same sign, so have the same sign at either end of
the curve. Therefore the maps we get from one end to the other from both trivializations
are either both orientation-preserving or both orientation-reversing; since the one from ${\Cal O}$
is orientation-preserving, so is the one from $U^\prime$. The point to this is that orientability
is a property of the bundle, not of the local trivializations we choose. (Although you need 
to be a little careful about how you interpret that statement...)

\ssk

For example, trivial bundles are orientable; the global trivialization $E\ra B\times \bbr^n$
will serve as our cover (i.e., ${\Cal O} = \{B\}$), and we give each fiber the
orientation induced by the inverse of the trivialization map (restricted to each fiber). Therefore, 
a non-orientable bundle cannot be trivial. Orientability turns out to be a crucial condition
in many of the theorems we will encounter as we go forward, especially when we get to learning
how to integrate over manifolds.

\msk

{\bf Boundary orientations:} The above discussion works fine for manifolds with boundary. 
So the concept of an orientable manifold with boundary make sense. If $M$ is orientable,
then we can use an orientation on $M$ to build an orientation for $T(\del M)$ as follows:
one of the homework problems talks about inward pointing tangent vectors at $\del M$; the same is
true for outward pointing vectors, the definition is independent of coordinate chart chosen.
If we cover $\del M$ by coordinate charts $(h_i,U_i)$, and take $M\setminus \del M$ to 
complete an open cover of $M$,
we can find a partition of unity subordinate to this cover. Choosing a trivialization of each $TU_i$
and a vector field $X_i$ over each $U_i$ which points outward at the boundary, then $X=\sum_ig_iX_i$
is a vector field on $M$ which points outward at every point of $\del M$. If $M$ is orientatble,
then we know how to choose an orientation on each fiber that is locally compatible. Look at the
orientations for $M$ built along $\del M$. We can compare them to the local orientations we can build 
{\it for} $\del M$ (i.e., choose local frames tangent to $\del M$) with the vector field $X$
appended at the end; this is a frame for $M$ since $X$ is not in the span of the frame for $\del M$.
The {\it induced} orientation for $\del M$ consists of the local frames for which this augmented
frame agrees with the orientation of $M$ at the points of $\del M$. Checking that local 
compatibility holds amounts to the fact that being outward pointing is independent of chart.
[The use of outward pointing vectors to build the induced orientation follows historical precedence, 
since the great integration theorems are always formulated in terms of ``outwardly-pointing normals''
at the boundary.]




\bsk

Some random, interesting but useless(?), facts:

\msk

Every $n$-manifold can be covered by at most $n+1$ charts. The minimum number of contractible 
open sets which cover $M$ is
called its {\it Lusternik-Schnirelmann category}, $LS(M)$. For example, $LS(S^n)=2$ for every $n$.
In also happens to be the minimal number of critical points that a function $f:M\rightarrow \bbr$
(whose critical points are discrete) can have.

\ssk

$\bbr^4$ has uncountably many non-differomorphic smooth structures; but since $\bbr^5$
has only one, crossing exotic $\bbr^4$'s with $\bbr$ always gives {\it standard} $\bbr^5$.

\ssk

Tangent bundles can be constructed for topological manifolds; the trick is to come up
with a characterization of the tangent bundle of a smooth manifold which doesn't mention
derivatives! Topological tangent bundles can then be used to attack questions such as
smoothability; it amounts to being able to put a ``linear'' structure on the topological tangent
bundle. 

\ssk

The {\it span} of a vector bundle is the maximum number of linearly independent vector fields
the the bundle can have. The span of a smooth manifold is the span of its tangent bundle.
A manifold $M$ has span $\geq 1$ \lra\ its Euler characteristic $\chi(M)=0$. Higher spans can
be detected by increasingly sophisticated tools from algebraic topology.

\ssk

Every orientable $3$-manifold $M^3$ is parallelizable; $TM^3$ is fiber-preserving diffeomorphic to
$M^3\times \bbr^3$ (Stiefel, 1936).

\msk



\vfill
\end

